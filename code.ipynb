{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_imagenet.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJuJM9aGuiBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing important libraries\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, GlobalAveragePooling2D, add\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import *\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as k\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# import wget\n",
        "\n",
        "import glob\n",
        "import pathlib\n",
        "import cv2\n",
        "import zipfile\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "import six\n",
        "\n",
        "num_classes = 200\n",
        "num_train = 90000\n",
        "# input image dimensions\n",
        "img_height, img_width = 64,64\n",
        "# The images are RGB.\n",
        "img_channels = 3\n",
        "num_validation = 10000\n",
        "batch_size = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9rMorNyAIHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Mount gdrive on colab\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaJGJkXGumaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      upload the zip file in gdrive. Mount it on colab and unzip it using the \n",
        "      following command\n",
        "\"\"\"\n",
        "!unzip './drive/My Drive/image-detect.zip' -d './drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQVEklGgQ_xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      Architeture for VGG16\n",
        "\"\"\"\n",
        "\n",
        "_input_ = Input(shape=(img_height, img_width, img_channels)) \n",
        "\n",
        "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(_input_)\n",
        "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv1)\n",
        "pool1  = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(pool1)\n",
        "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv3)\n",
        "pool2  = MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(pool2)\n",
        "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv5)\n",
        "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv6)\n",
        "pool3  = MaxPooling2D((2, 2))(conv7)\n",
        "\n",
        "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(pool3)\n",
        "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv8)\n",
        "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv9)\n",
        "pool4  = MaxPooling2D((2, 2))(conv10)\n",
        "\n",
        "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(pool4)\n",
        "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv11)\n",
        "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\" , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(conv12)\n",
        "pool5  = MaxPooling2D((2, 2))(conv13)\n",
        "\n",
        "flat   = Flatten()(pool5)\n",
        "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
        "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
        "output = Dense(200, activation=\"softmax\")(dense2)\n",
        "\n",
        "vgg16_model  = Model(inputs=_input_, outputs=output)\n",
        "model = vgg16_model\n",
        "\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_9cWI0W5f1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Architecture for ResNet-34\n",
        "\"\"\"\n",
        "\n",
        "# # Model building\n",
        "ip = Input(shape=(img_height, img_width, img_channels))\n",
        "\n",
        "# Block 1\n",
        "layer0 = Conv2D(32, (3,3), padding='same', kernel_initializer=\"VarianceScaling\"\n",
        "                    ,kernel_regularizer=tf.keras.regularizers.l2(2e-4))(ip)\n",
        "layer0 = BatchNormalization()(layer0)\n",
        "layer0 = Activation('relu')(layer0)\n",
        "\n",
        "skip_connection_1 = layer0\n",
        "\n",
        "# # Block 2\n",
        "\n",
        "layer1 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer0)\n",
        "layer1 = BatchNormalization()(layer1)\n",
        "layer1 = Activation('relu')(layer1)\n",
        "\n",
        "layer2 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer1)\n",
        "layer2 = BatchNormalization()(layer2)\n",
        "layer2 = Activation('relu')(layer2)\n",
        "\n",
        "layer3 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer2)\n",
        "layer3 = BatchNormalization()(layer3)\n",
        "layer3 = Activation('relu')(layer3)\n",
        "\n",
        "layer4 = Conv2D(128, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer3)\n",
        "layer4 = BatchNormalization()(layer4)\n",
        "layer4 = Activation('relu')(layer4)\n",
        "\n",
        "layer5 = concatenate([skip_connection_1, layer4])\n",
        "layer5 = BatchNormalization()(layer5)\n",
        "layer5 = Activation('relu')(layer5)\n",
        "layer5 = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
        "\n",
        "skip_connection_2 = layer5\n",
        "\n",
        "# # Block 3\n",
        "\n",
        "layer6 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer5)\n",
        "layer6 = BatchNormalization()(layer6)\n",
        "layer6 = Activation('relu')(layer6)\n",
        "\n",
        "layer7 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer6)\n",
        "layer7 = BatchNormalization()(layer7)\n",
        "layer7 = Activation('relu')(layer7)\n",
        "\n",
        "layer8 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer7)\n",
        "layer8 = BatchNormalization()(layer8)\n",
        "layer8 = Activation('relu')(layer8)\n",
        "\n",
        "layer9 = Conv2D(256, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer8)\n",
        "layer9 = BatchNormalization()(layer9)\n",
        "layer9 = Activation('relu')(layer9)\n",
        "\n",
        "layer10 = concatenate([skip_connection_2, layer9])\n",
        "layer10 = BatchNormalization()(layer10)\n",
        "layer10 = Activation('relu')(layer10)\n",
        "layer10 = MaxPooling2D(pool_size=(2, 2))(layer10)\n",
        "\n",
        "skip_connection_3 = layer10\n",
        "\n",
        "\n",
        "# # Block 4\n",
        "\n",
        "layer11 = Conv2D(512, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer10)\n",
        "layer11 = BatchNormalization()(layer11)\n",
        "layer11 = Activation('relu')(layer11)\n",
        "\n",
        "layer12 = Conv2D(512, (3,3), padding='same', kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer11)\n",
        "layer12 = BatchNormalization()(layer12)\n",
        "layer12 = Activation('relu')(layer12)\n",
        "\n",
        "layer13 = Conv2D(512, (3,3), padding='same',kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer12)\n",
        "layer13 = BatchNormalization()(layer13)\n",
        "layer13 = Activation('relu')(layer13)\n",
        "\n",
        "layer14 = Conv2D(512, (3,3), padding='same',kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer13)\n",
        "layer14 = BatchNormalization()(layer14)\n",
        "layer14 = Activation('relu')(layer14)\n",
        "\n",
        "layer15 = concatenate([skip_connection_3, layer14])\n",
        "layer15 = BatchNormalization()(layer15)\n",
        "layer15 = Activation('relu')(layer15)\n",
        "layer15 = MaxPooling2D(pool_size=(2, 2))(layer15)\n",
        "\n",
        "\n",
        "# #Layer 16\n",
        "layer16 = Conv2D(num_classes, (1,1), padding='same',kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer15)\n",
        "layer16 = GlobalAveragePooling2D()(layer16)\n",
        "\n",
        "# # #Output Layer\n",
        "output = Activation('softmax')(layer16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm0mph4S5glN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Architecture for DenseNet-50\n",
        "\"\"\"\n",
        "\n",
        "def space_to_depth_x2(x):\n",
        "    return tf.nn.space_to_depth(x, block_size=2)\n",
        "\n",
        "ip = Input(shape=(None, None, img_channels))\n",
        "\n",
        "# Block 1\n",
        "\n",
        "layer1 = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1' , kernel_initializer=\"VarianceScaling\" , kernel_regularizer=tf.keras.regularizers.l2(2e-4))(ip)\n",
        "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
        "layer1 = Activation(\"relu\")(layer1)\n",
        "\n",
        "layer2 = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2' , kernel_initializer=\"VarianceScaling\" , kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer1)\n",
        "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
        "layer2 = Activation(\"relu\")(layer2)\n",
        "\n",
        "layer3 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3' , kernel_initializer=\"VarianceScaling\" , kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer2)\n",
        "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
        "layer3 = Activation(\"relu\")(layer3)\n",
        "\n",
        "layer4 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_4' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer3)\n",
        "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
        "layer4 = Activation(\"relu\")(layer4)\n",
        "\n",
        "layer5 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_5' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer4)\n",
        "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
        "layer5 = Activation(\"relu\")(layer5)\n",
        "\n",
        "layer6 = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
        "\n",
        "skip_connection_1 = layer6\n",
        "\n",
        "# Block 2\n",
        "\n",
        "layer7 = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_7' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer6)\n",
        "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
        "layer7 = Activation(\"relu\")(layer7)\n",
        "\n",
        "layer8 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_8' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer7)\n",
        "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
        "layer8 = Activation(\"relu\")(layer8)\n",
        "\n",
        "layer9 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_9' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer8)\n",
        "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
        "layer9 = Activation(\"relu\")(layer9)\n",
        "\n",
        "layer10 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_10' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer9)\n",
        "layer10 = BatchNormalization(name='norm_10')(layer10)\n",
        "layer10 = Activation(\"relu\")(layer10)\n",
        "\n",
        "layer11 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_11' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer10)\n",
        "layer11 = BatchNormalization(name='norm_11')(layer11)\n",
        "layer11 = Activation(\"relu\")(layer11)\n",
        "\n",
        "layer12 = MaxPooling2D(pool_size=(2, 2))(layer11)\n",
        "\n",
        "skip_connection_1 = Lambda(space_to_depth_x2)(skip_connection_1)\n",
        "\n",
        "layer13 = concatenate([skip_connection_1, layer12])\n",
        "\n",
        "skip_connection_2 = layer13\n",
        "\n",
        "# Block 3\n",
        "\n",
        "layer14 = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_14' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer13)\n",
        "layer14 = BatchNormalization(name='norm_14')(layer14)\n",
        "layer14 = Activation(\"relu\")(layer14)\n",
        "\n",
        "layer15 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_15' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer14)\n",
        "layer15 = BatchNormalization(name='norm_15')(layer15)\n",
        "layer15 = Activation(\"relu\")(layer15)\n",
        "\n",
        "layer16 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_16' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer15)\n",
        "layer16 = BatchNormalization(name='norm_16')(layer16)\n",
        "layer16 = Activation(\"relu\")(layer16)\n",
        "\n",
        "layer17 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_17' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer16)\n",
        "layer17 = BatchNormalization(name='norm_17')(layer17)\n",
        "layer17 = Activation(\"relu\")(layer17)\n",
        "\n",
        "layer18 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18' , kernel_initializer=\"VarianceScaling\",kernel_regularizer=tf.keras.regularizers.l2(2e-4))(layer17)\n",
        "layer18 = BatchNormalization(name='norm_18')(layer18)\n",
        "layer18 = Activation(\"relu\")(layer18)\n",
        "\n",
        "layer19 = MaxPooling2D(pool_size=(2, 2))(layer18)\n",
        "\n",
        "skip_connection_2 = Lambda(space_to_depth_x2)(skip_connection_2)\n",
        "\n",
        "layer20 = concatenate([skip_connection_2, layer19])\n",
        "\n",
        "layer21 = Conv2D(num_classes, (1,1), name='conv_21')(layer20)\n",
        "layer21 = BatchNormalization(name='norm_21')(layer21)\n",
        "\n",
        "layer22 = GlobalAveragePooling2D(data_format=None)(layer21)\n",
        "\n",
        "layer23 = Activation('softmax')(layer22)\n",
        "\n",
        "output = layer23\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35uC0jd8uu43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    A simple convnet architecture\n",
        "\"\"\"\n",
        "\"\"\"Block 1\"\"\"\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), padding='same', input_shape=(img_height,img_width,img_channels)))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Activation('relu'))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Block 2\"\"\"\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Activation('relu'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Block 3\"\"\"\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Activation('relu'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Block 4\"\"\"\n",
        "model.add(Conv2D(256, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Conv2D(512, (3, 3), strides=(1,1), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Activation('relu'))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Block 5\"\"\"\n",
        "model.add(Flatten())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Dense(4096))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Activation('relu'))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Block Test\"\"\"\n",
        "model.add(Dense(1024))\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(BatchNormalization())\n",
        "print(model.layers[-1].output_shape)\n",
        "model.add(Activation('relu'))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Output Layer\"\"\"\n",
        "model.add(Dense(num_classes))\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "\"\"\"Loss Layer\"\"\"\n",
        "model.add(Activation('softmax'))\n",
        "print(model.layers[-1].output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wB-M_8w8Frq",
        "colab_type": "text"
      },
      "source": [
        "Reading the contents of the file val_annotations.txt where entries are \n",
        "separated by '\\t'. There are no column names but annotated using \n",
        "\n",
        "\n",
        "**names**=['File', 'Class', 'X', 'Y', 'H', 'W'] where File is the file name,\n",
        "\n",
        "**Class** is the true class label and 'X', 'Y', 'H', 'W' is for the four\n",
        "numeric values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDzgBVeKu3MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = pd.read_csv('./drive/My Drive/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True) \n",
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB663VPvu46x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      For data augmentation \n",
        "\"\"\"\n",
        "def CustomImageDataGen(input_img):\n",
        "  \"\"\"\n",
        "  Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
        "  e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n",
        "  image.\n",
        "  \"\"\"\n",
        "  sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "  \n",
        "  seq = iaa.Sequential([\n",
        "      iaa.Fliplr(0.5), # horizontal flips\n",
        "      iaa.Flipud(0.2), # vertical flips\n",
        "      \n",
        "      # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "      # But we only blur about 50% of all images.\n",
        "      sometimes(iaa.GaussianBlur(sigma=(0, 2.0))),\n",
        "      \n",
        "      # crop images by -10% to 20% of their height/width\n",
        "      sometimes(iaa.CropAndPad(\n",
        "          percent=(-0.1, 0.2),\n",
        "          pad_mode=ia.ALL,\n",
        "          pad_cval=(0, 255)\n",
        "        )),\n",
        "      \n",
        "      # Apply affine transformations to some of the images\n",
        "      # - scale to 80-120% of image height/width (each axis independently)\n",
        "      # - translate by -20 to +20 relative to height/width (per axis)\n",
        "      # - rotate by -45 to +45 degrees\n",
        "      # - shear by -16 to +16 degrees\n",
        "      # - order: use nearest neighbour or bilinear interpolation (fast)\n",
        "      # - mode: use any available mode to fill newly created pixels\n",
        "      #         see API or scikit-image for which modes are available\n",
        "      # - cval: if the mode is constant, then use a random brightness\n",
        "      #         for the newly created pixels (e.g. sometimes black,\n",
        "      #         sometimes white)\n",
        "      sometimes(iaa.Affine(\n",
        "          scale={\"x\": (0.8, 1.5), \"y\": (0.8, 1.5)},\n",
        "          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "          rotate=(-45, 45),\n",
        "          shear=(-16, 16),\n",
        "          order=[0, 1],\n",
        "          cval=(0, 255),\n",
        "          mode=ia.ALL\n",
        "      )),\n",
        "      \n",
        "      #drop 2-5% percent of the original size, leading to large dropped\n",
        "      # rectangles.\n",
        "      sometimes(iaa.CoarseDropout(\n",
        "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
        "                        per_channel=0.2\n",
        "                    )),\n",
        "                \n",
        "      # Make some images brighter and some darker.\n",
        "      # In 20% of all cases, we sample the multiplier once per channel,\n",
        "      # which can end up changing the color of the images.\n",
        "      sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.2)),\n",
        "      \n",
        "      #Improve or worsen the contrast of images.\n",
        "      #Comment it out after third model run (extreme saturation)\n",
        "      sometimes(iaa.ContrastNormalization((0.75, 1.5), per_channel=0.5)), \n",
        "     ],\n",
        "     # do all of the above augmentations in random order\n",
        "     random_order = True) # apply augmenters in random order\n",
        "  \n",
        "  output_img = seq.augment_image(input_img)\n",
        "  return output_img\n",
        "\n",
        "\"\"\"\n",
        "      rescale is a value by which we will multiply the data before any other \n",
        "      processing. Our original images consist in RGB coefficients in the 0-255, \n",
        "      but such values would be too high for our models to process \n",
        "      (given a typical learning rate), so we target values between 0 and 1 \n",
        "      instead by scaling with a 1/255. factor.\n",
        "\"\"\"\n",
        "train_datagen = ImageDataGenerator(rescale=1/255., preprocessing_function = CustomImageDataGen)\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQFsAHpE7Hc9",
        "colab_type": "text"
      },
      "source": [
        "**Directory**: Directory where the data is located. If labels is \"inferred\",\n",
        "it should contain subdirectories, each containing images for a class. \n",
        "\n",
        "\n",
        "**Target_size**: Size to resize images to after they are read from disk.\n",
        "\n",
        "\n",
        "**Batch_size**: Size of the batches of data taken into account for an epoch.\n",
        "\n",
        "\n",
        "**Class_mode**: One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. \n",
        "\n",
        "\n",
        "**Default**: \"categorical\". Determines the type of label arrays that are \n",
        "returned: - \"categorical\" will be one-hot encoded labels \n",
        "\n",
        "**shuffle**: Whether to shuffle the data. Default: True. If set to False, sorts the data in alphanumeric order.\n",
        "\n",
        "**seed**: Optional random seed for shuffling and transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EghxGyyyNbNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./drive/My Drive/train/', \n",
        "                                                    target_size=(img_width, img_height), \n",
        "                                                    batch_size=batch_size, \n",
        "                                                    class_mode='categorical', \n",
        "                                                    shuffle=True, seed=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOkTowCpNko0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./drive/My Drive/val/images/', \n",
        "                                                         x_col='File', y_col='Class', \n",
        "                                                         target_size=(img_width, img_height),\n",
        "                                                         class_mode='categorical', \n",
        "                                                         batch_size=batch_size, \n",
        "                                                         shuffle=False, seed=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45OowwPXu7Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      For visualizing the augmented images \n",
        "\"\"\"\n",
        "x_batch, y_batch = next(train_generator)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='bicubic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QKrVPqku9Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[ip], outputs=[output])\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXyS1KMc3bGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"for architecture 1 and VGG_16\n",
        "\"\"\"\n",
        "# Compile the Model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              # optimizer= RMSprop(lr= 0.0001, epsilon=1e-08),\n",
        "              # optimizer= Adam(lr= 0.0001, epsilon=1e-08),\n",
        "              optimizer = SGD( learning_rate=0.001, momentum=0.9, nesterov=True),\n",
        "              metrics=['acc'])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=10, verbose=1, min_lr=0.001) #on plateaus\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20,\n",
        "                          verbose=1, mode='auto')\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=\"./drive/My Drive/Network1_colab.hdf5\", verbose=1, save_best_only = False, monitor=\"val_loss\")\n",
        "callbacks_list = [earlystop,reduce_lr,checkpoint]\n",
        "\n",
        "model = load_model(\"./drive/My Drive/Network1_colab.hdf5\")\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs = 75,\n",
        "                    steps_per_epoch= num_train // batch_size,\n",
        "                    validation_steps= num_validation // batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose=1, callbacks=callbacks_list\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAoYqvf-u_An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"for Architecture 2 and architecture 3\n",
        "\"\"\"\n",
        "reduce_lr = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,\n",
        "                          verbose=1, mode='auto')\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=\"./drive/My Drive/Network2_colab.hdf5\", verbose=1, save_best_only=False, monitor=\"val_loss\")\n",
        "\n",
        "model = load_model(\"./drive/My Drive/Network2_colab.hdf5\" , custom_objects={'tf': tf})\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              # optimizer= Adam(lr= 0.001, epsilon=1e-08),\n",
        "              optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])\n",
        "callbacks_list = [earlystop,reduce_lr,checkpoint]\n",
        "\n",
        "model.fit_generator(train_generator, epochs=75, validation_data=validation_generator, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZumItGGbvBsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(\"./drive/My Drive/Network2_colab.hdf5\" , custom_objects={'tf': tf})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjqNHNL4Q1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_generator, epochs=75, validation_data=validation_generator, verbose=1, callbacks=callbacks_list) # steps_per_epoch=3000, validation_steps=3000,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYCov-YavFBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Evaluating the trained model on validation data\"\"\"\n",
        "validation_steps_per_epoch = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
        "score = model.evaluate_generator(validation_generator, verbose=1, steps=validation_steps_per_epoch)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crtZlcFV4CAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediction based on validation data\n",
        "pred=model.predict_generator(validation_generator, steps= np.ceil(num_validation/batch_size), verbose=1)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "# Predicted class indices of 1st 10 val images\n",
        "predicted_class_indices[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-meZG1PC5qr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True class indices of 1st 10 validation images\n",
        "validation_generator.classes[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVoapkX-5sdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicted classes from their indices\n",
        "labels = (validation_generator.class_indices)\n",
        "labels = dict((v,x) for x,v in labels.items())\n",
        "predictions = [labels[x] for x in predicted_class_indices]\n",
        "predictions[:10] #first 10 of them\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9c8MoRl5uKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Validation class names from words.txt\n",
        "class_to_name = dict()\n",
        "file = open('./drive/My Drive/words.txt','r')\n",
        "data= file.readlines()\n",
        "for line in data:\n",
        "  words = line.strip('\\n').split('\\t')\n",
        "  class_to_name[words[0]] = words[1].split(',')[0]\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e5SDgQb5wK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Asserting Validation Class names from words.txt\n",
        "validation_class_names={}\n",
        "for _class in validation_generator.class_indices.keys():\n",
        "  validation_class_names.update({_class : class_to_name[_class]})\n",
        "  \n",
        "# Classification Report of val classes\n",
        "print(classification_report(validation_generator.classes, predicted_class_indices,\n",
        "                            #target_names=validation_generator.class_indices.keys(),\n",
        "                            target_names=validation_class_names.values(),\n",
        "                            digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRsua2VA5x48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" A list of all test images\"\"\"\n",
        "classes=[]\n",
        "data_dir = pathlib.Path('./drive/My Drive/train/')\n",
        "classes = sorted([item.name for item in data_dir.glob('*')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FZq9IPK50W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z=[]\n",
        "file1 = open(r\"./drive/My Drive/prediction_network2.txt\",\"w+\")\n",
        "for file in glob.glob(\"./drive/My Drive/test/images/*.JPEG\"):\n",
        "    images = [cv2.imread(file)]\n",
        "    processed_image=np.divide(images[:],255.0)\n",
        "    prediction_probs = model.predict(processed_image)\n",
        "    prediction = int(np.argmax(prediction_probs.reshape(-1)))\n",
        "    file1.write('{},{}\\n'.format(file[29:], classes[prediction]))\n",
        "    z.append(classes[prediction])\n",
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQXIVrDiO-4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
